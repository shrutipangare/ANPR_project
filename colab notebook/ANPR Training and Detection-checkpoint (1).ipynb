{"cells":[{"cell_type":"markdown","metadata":{"id":"QUANWN3rpfC9"},"source":["# 0. Setup Paths"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":668,"status":"ok","timestamp":1653115488273,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"146BB11JpfDA"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1653115490538,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"42hJEdo_pfDB"},"outputs":[],"source":["CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n","PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'label_map.pbtxt'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":414,"status":"ok","timestamp":1653115494141,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"hbPhYVy_pfDB"},"outputs":[],"source":["paths = {\n","    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n","    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n","    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n","    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n","    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n","    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n","    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n","    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n","    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n","    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n","    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n","    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n"," }"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1653115497363,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"LwhWZMI0pfDC"},"outputs":[],"source":["files = {\n","    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n","    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n","    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n","}"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1541,"status":"ok","timestamp":1653115501039,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"HR-TfDGrpfDC"},"outputs":[],"source":["for path in paths.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"]},{"cell_type":"markdown","metadata":{"id":"OLU-rs_ipfDE"},"source":["# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2tKIFo6p7-f"},"outputs":[],"source":["# https://www.tensorflow.org/install/source_windows"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":376,"status":"ok","timestamp":1653115504409,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"K-Cmz2edpfDE","scrolled":true},"outputs":[],"source":["if os.name=='nt':\n","    !pip install wget\n","    import wget"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"q1FpD77D-0UO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653115511924,"user_tz":-330,"elapsed":5296,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"}},"outputId":"1a44dfc1-b669-42ff-a315-4759ee607e1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","Successfully installed pip-22.1\n"]}],"source":["pip install --upgrade pip "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25108,"status":"ok","timestamp":1653115542407,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"iA1DIq5OpfDE","outputId":"ec3ef7b0-951e-459e-b16c-1a1f96ad422b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Tensorflow/models'...\n","remote: Enumerating objects: 73045, done.\u001b[K\n","remote: Counting objects: 100% (88/88), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 73045 (delta 35), reused 54 (delta 20), pack-reused 72957\u001b[K\n","Receiving objects: 100% (73045/73045), 579.27 MiB | 26.58 MiB/s, done.\n","Resolving deltas: 100% (51690/51690), done.\n"]}],"source":["if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n","    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83817,"status":"ok","timestamp":1653115636917,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"rJjMHbnDs3Tv","outputId":"3c97845b-3ab8-4ac5-d04a-2d4bb983c1cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n","Processing /content/Tensorflow/models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting apache-beam\n","  Downloading apache_beam-2.38.0-cp37-cp37m-manylinux2010_x86_64.whl (10.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.9/25.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting tensorflow-text~=2.9.0\n","  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow~=2.9.0\n","  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.6/237.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting requests<3.0.0,>=2.24.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.5/253.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.17.3)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.4-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.1/508.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.46.1)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.4.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.2.0)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (3.0.9)\n","Collecting tensorflow-io-gcs-filesystem==0.26.0\n","  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Collecting protobuf<4,>=3.12.2\n","  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Collecting keras\n","  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Collecting flatbuffers<2,>=1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Building wheels for collected packages: object-detection, avro-python3, dill, py-cpuinfo, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21914870 sha256=8c5eebb9b574178ccf45d7df42d6e9a9f97acafa4bffbff562014fbeed08b9d0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8a2eg_i6/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=7da9dde3964004bfc263c23926b982d2a8d93d401f96ffcf48053ad3369cfa04\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=5780b698fc8a4df7a4828ace93a5a9ce17b7d474fccc9057c882d165eb5e386d\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=251b9efa0515dc66b8fbe1541b28f6821994933537dcd8af1c5dc3ae4d71366c\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6a509a11c6345ac49cc510948b692ccc35d008797b0b86c41885a9dd4a6b368e\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection avro-python3 dill py-cpuinfo seqeval\n","Installing collected packages: sentencepiece, py-cpuinfo, keras, flatbuffers, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorflow-addons, requests, pyyaml, pymongo, protobuf, portalocker, orjson, opencv-python-headless, gast, fastavro, dill, colorama, cloudpickle, avro-python3, tf-slim, tensorflow_io, sacrebleu, proto-plus, hdfs, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: tensorflow-io-gcs-filesystem\n","    Found existing installation: tensorflow-io-gcs-filesystem 0.25.0\n","    Uninstalling tensorflow-io-gcs-filesystem-0.25.0:\n","      Successfully uninstalled tensorflow-io-gcs-filesystem-0.25.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.1.1\n","    Uninstalling pymongo-4.1.1:\n","      Successfully uninstalled pymongo-4.1.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n","    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n","      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed apache-beam-2.38.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.12 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.4 protobuf-3.20.1 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.0 tensorflow-2.9.0 tensorflow-addons-0.16.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 tensorflow_io-0.26.0 tf-models-official-2.9.2 tf-slim-1.1.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Install Tensorflow Object Detection \n","if os.name=='posix':  \n","    !apt-get install protobuf-compiler\n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n","    \n","if os.name=='nt':\n","    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.19.3-win64.zip\"\n","    wget.download(url)\n","    !move protoc-3.19.3-win64.zip {paths['PROTOC_PATH']}\n","    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.19.3-win64.zip\n","    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n","    !cd Tensorflow/models/research/slim && pip install -e . "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41393,"status":"ok","timestamp":1653115698430,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"kGPe_1UPp7-o","outputId":"1dd0d8eb-3e96-4615-ff3e-86d948c5cb4c","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.13: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-05-21 06:47:42.790500: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0521 06:47:43.164840 139739648632704 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.58s\n","I0521 06:47:43.432792 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.58s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n","I0521 06:47:43.990904 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.28s\n","I0521 06:47:44.272343 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.28s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n","I0521 06:47:44.522448 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.0s\n","I0521 06:47:46.525174 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.0s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0521 06:47:46.526213 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","I0521 06:47:46.550440 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0521 06:47:46.566006 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0521 06:47:46.582200 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n","I0521 06:47:46.685547 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n","I0521 06:47:46.786125 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n","I0521 06:47:46.903228 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n","I0521 06:47:47.008169 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","I0521 06:47:47.113499 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0521 06:47:47.145117 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0521 06:47:47.332674 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0521 06:47:47.332939 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0521 06:47:47.333042 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0521 06:47:47.336134 139739648632704 efficientnet_model.py:143] round_filter input=32 output=32\n","I0521 06:47:47.355421 139739648632704 efficientnet_model.py:143] round_filter input=32 output=32\n","I0521 06:47:47.355601 139739648632704 efficientnet_model.py:143] round_filter input=16 output=16\n","I0521 06:47:47.425078 139739648632704 efficientnet_model.py:143] round_filter input=16 output=16\n","I0521 06:47:47.425288 139739648632704 efficientnet_model.py:143] round_filter input=24 output=24\n","I0521 06:47:47.601509 139739648632704 efficientnet_model.py:143] round_filter input=24 output=24\n","I0521 06:47:47.601725 139739648632704 efficientnet_model.py:143] round_filter input=40 output=40\n","I0521 06:47:47.778167 139739648632704 efficientnet_model.py:143] round_filter input=40 output=40\n","I0521 06:47:47.778381 139739648632704 efficientnet_model.py:143] round_filter input=80 output=80\n","I0521 06:47:48.049434 139739648632704 efficientnet_model.py:143] round_filter input=80 output=80\n","I0521 06:47:48.049638 139739648632704 efficientnet_model.py:143] round_filter input=112 output=112\n","I0521 06:47:48.478882 139739648632704 efficientnet_model.py:143] round_filter input=112 output=112\n","I0521 06:47:48.479103 139739648632704 efficientnet_model.py:143] round_filter input=192 output=192\n","I0521 06:47:48.849231 139739648632704 efficientnet_model.py:143] round_filter input=192 output=192\n","I0521 06:47:48.849484 139739648632704 efficientnet_model.py:143] round_filter input=320 output=320\n","I0521 06:47:48.951173 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0521 06:47:48.989435 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:47:49.047522 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0521 06:47:49.047754 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0521 06:47:49.047838 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0521 06:47:49.049726 139739648632704 efficientnet_model.py:143] round_filter input=32 output=32\n","I0521 06:47:49.068223 139739648632704 efficientnet_model.py:143] round_filter input=32 output=32\n","I0521 06:47:49.068410 139739648632704 efficientnet_model.py:143] round_filter input=16 output=16\n","I0521 06:47:49.214591 139739648632704 efficientnet_model.py:143] round_filter input=16 output=16\n","I0521 06:47:49.214805 139739648632704 efficientnet_model.py:143] round_filter input=24 output=24\n","I0521 06:47:49.466688 139739648632704 efficientnet_model.py:143] round_filter input=24 output=24\n","I0521 06:47:49.466875 139739648632704 efficientnet_model.py:143] round_filter input=40 output=40\n","I0521 06:47:49.728602 139739648632704 efficientnet_model.py:143] round_filter input=40 output=40\n","I0521 06:47:49.728815 139739648632704 efficientnet_model.py:143] round_filter input=80 output=80\n","I0521 06:47:50.108021 139739648632704 efficientnet_model.py:143] round_filter input=80 output=80\n","I0521 06:47:50.108232 139739648632704 efficientnet_model.py:143] round_filter input=112 output=112\n","I0521 06:47:50.478262 139739648632704 efficientnet_model.py:143] round_filter input=112 output=112\n","I0521 06:47:50.478465 139739648632704 efficientnet_model.py:143] round_filter input=192 output=192\n","I0521 06:47:50.905991 139739648632704 efficientnet_model.py:143] round_filter input=192 output=192\n","I0521 06:47:50.906211 139739648632704 efficientnet_model.py:143] round_filter input=320 output=320\n","I0521 06:47:51.089424 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0521 06:47:51.123195 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:47:51.193886 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0521 06:47:51.194106 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0521 06:47:51.194180 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0521 06:47:51.195962 139739648632704 efficientnet_model.py:143] round_filter input=32 output=32\n","I0521 06:47:51.213689 139739648632704 efficientnet_model.py:143] round_filter input=32 output=32\n","I0521 06:47:51.213858 139739648632704 efficientnet_model.py:143] round_filter input=16 output=16\n","I0521 06:47:51.352437 139739648632704 efficientnet_model.py:143] round_filter input=16 output=16\n","I0521 06:47:51.352643 139739648632704 efficientnet_model.py:143] round_filter input=24 output=24\n","I0521 06:47:51.610000 139739648632704 efficientnet_model.py:143] round_filter input=24 output=24\n","I0521 06:47:51.610185 139739648632704 efficientnet_model.py:143] round_filter input=40 output=48\n","I0521 06:47:51.858532 139739648632704 efficientnet_model.py:143] round_filter input=40 output=48\n","I0521 06:47:51.858769 139739648632704 efficientnet_model.py:143] round_filter input=80 output=88\n","I0521 06:47:52.204565 139739648632704 efficientnet_model.py:143] round_filter input=80 output=88\n","I0521 06:47:52.204762 139739648632704 efficientnet_model.py:143] round_filter input=112 output=120\n","I0521 06:47:52.549446 139739648632704 efficientnet_model.py:143] round_filter input=112 output=120\n","I0521 06:47:52.549682 139739648632704 efficientnet_model.py:143] round_filter input=192 output=208\n","I0521 06:47:52.983241 139739648632704 efficientnet_model.py:143] round_filter input=192 output=208\n","I0521 06:47:52.983441 139739648632704 efficientnet_model.py:143] round_filter input=320 output=352\n","I0521 06:47:53.152833 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I0521 06:47:53.191789 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:47:53.255389 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0521 06:47:53.255572 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0521 06:47:53.255668 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0521 06:47:53.257369 139739648632704 efficientnet_model.py:143] round_filter input=32 output=40\n","I0521 06:47:53.275341 139739648632704 efficientnet_model.py:143] round_filter input=32 output=40\n","I0521 06:47:53.275495 139739648632704 efficientnet_model.py:143] round_filter input=16 output=24\n","I0521 06:47:53.409844 139739648632704 efficientnet_model.py:143] round_filter input=16 output=24\n","I0521 06:47:53.410030 139739648632704 efficientnet_model.py:143] round_filter input=24 output=32\n","I0521 06:47:53.853599 139739648632704 efficientnet_model.py:143] round_filter input=24 output=32\n","I0521 06:47:53.853793 139739648632704 efficientnet_model.py:143] round_filter input=40 output=48\n","I0521 06:47:54.138420 139739648632704 efficientnet_model.py:143] round_filter input=40 output=48\n","I0521 06:47:54.138638 139739648632704 efficientnet_model.py:143] round_filter input=80 output=96\n","I0521 06:47:54.565140 139739648632704 efficientnet_model.py:143] round_filter input=80 output=96\n","I0521 06:47:54.565342 139739648632704 efficientnet_model.py:143] round_filter input=112 output=136\n","I0521 06:47:55.020295 139739648632704 efficientnet_model.py:143] round_filter input=112 output=136\n","I0521 06:47:55.020513 139739648632704 efficientnet_model.py:143] round_filter input=192 output=232\n","I0521 06:47:55.569966 139739648632704 efficientnet_model.py:143] round_filter input=192 output=232\n","I0521 06:47:55.570175 139739648632704 efficientnet_model.py:143] round_filter input=320 output=384\n","I0521 06:47:55.757093 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I0521 06:47:55.791520 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:47:55.867061 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0521 06:47:55.867263 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0521 06:47:55.867358 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0521 06:47:55.869141 139739648632704 efficientnet_model.py:143] round_filter input=32 output=48\n","I0521 06:47:55.889523 139739648632704 efficientnet_model.py:143] round_filter input=32 output=48\n","I0521 06:47:55.889729 139739648632704 efficientnet_model.py:143] round_filter input=16 output=24\n","I0521 06:47:56.061584 139739648632704 efficientnet_model.py:143] round_filter input=16 output=24\n","I0521 06:47:56.061791 139739648632704 efficientnet_model.py:143] round_filter input=24 output=32\n","I0521 06:47:56.410732 139739648632704 efficientnet_model.py:143] round_filter input=24 output=32\n","I0521 06:47:56.410923 139739648632704 efficientnet_model.py:143] round_filter input=40 output=56\n","I0521 06:47:56.780247 139739648632704 efficientnet_model.py:143] round_filter input=40 output=56\n","I0521 06:47:56.780455 139739648632704 efficientnet_model.py:143] round_filter input=80 output=112\n","I0521 06:47:57.322713 139739648632704 efficientnet_model.py:143] round_filter input=80 output=112\n","I0521 06:47:57.322898 139739648632704 efficientnet_model.py:143] round_filter input=112 output=160\n","I0521 06:47:57.833916 139739648632704 efficientnet_model.py:143] round_filter input=112 output=160\n","I0521 06:47:57.834113 139739648632704 efficientnet_model.py:143] round_filter input=192 output=272\n","I0521 06:47:58.514944 139739648632704 efficientnet_model.py:143] round_filter input=192 output=272\n","I0521 06:47:58.515131 139739648632704 efficientnet_model.py:143] round_filter input=320 output=448\n","I0521 06:47:58.675742 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I0521 06:47:58.705977 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:47:58.787988 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0521 06:47:58.788171 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0521 06:47:58.788251 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0521 06:47:58.789962 139739648632704 efficientnet_model.py:143] round_filter input=32 output=48\n","I0521 06:47:58.807580 139739648632704 efficientnet_model.py:143] round_filter input=32 output=48\n","I0521 06:47:58.807759 139739648632704 efficientnet_model.py:143] round_filter input=16 output=24\n","I0521 06:47:59.009689 139739648632704 efficientnet_model.py:143] round_filter input=16 output=24\n","I0521 06:47:59.009896 139739648632704 efficientnet_model.py:143] round_filter input=24 output=40\n","I0521 06:47:59.426614 139739648632704 efficientnet_model.py:143] round_filter input=24 output=40\n","I0521 06:47:59.426826 139739648632704 efficientnet_model.py:143] round_filter input=40 output=64\n","I0521 06:48:00.085731 139739648632704 efficientnet_model.py:143] round_filter input=40 output=64\n","I0521 06:48:00.085964 139739648632704 efficientnet_model.py:143] round_filter input=80 output=128\n","I0521 06:48:00.685106 139739648632704 efficientnet_model.py:143] round_filter input=80 output=128\n","I0521 06:48:00.685290 139739648632704 efficientnet_model.py:143] round_filter input=112 output=176\n","I0521 06:48:01.279000 139739648632704 efficientnet_model.py:143] round_filter input=112 output=176\n","I0521 06:48:01.279217 139739648632704 efficientnet_model.py:143] round_filter input=192 output=304\n","I0521 06:48:02.095902 139739648632704 efficientnet_model.py:143] round_filter input=192 output=304\n","I0521 06:48:02.096113 139739648632704 efficientnet_model.py:143] round_filter input=320 output=512\n","I0521 06:48:02.382771 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I0521 06:48:02.415685 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:48:02.507556 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0521 06:48:02.507761 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0521 06:48:02.507843 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0521 06:48:02.509654 139739648632704 efficientnet_model.py:143] round_filter input=32 output=56\n","I0521 06:48:02.527891 139739648632704 efficientnet_model.py:143] round_filter input=32 output=56\n","I0521 06:48:02.528068 139739648632704 efficientnet_model.py:143] round_filter input=16 output=32\n","I0521 06:48:02.732482 139739648632704 efficientnet_model.py:143] round_filter input=16 output=32\n","I0521 06:48:02.732686 139739648632704 efficientnet_model.py:143] round_filter input=24 output=40\n","I0521 06:48:03.277604 139739648632704 efficientnet_model.py:143] round_filter input=24 output=40\n","I0521 06:48:03.277842 139739648632704 efficientnet_model.py:143] round_filter input=40 output=72\n","I0521 06:48:03.820106 139739648632704 efficientnet_model.py:143] round_filter input=40 output=72\n","I0521 06:48:03.820298 139739648632704 efficientnet_model.py:143] round_filter input=80 output=144\n","I0521 06:48:04.558659 139739648632704 efficientnet_model.py:143] round_filter input=80 output=144\n","I0521 06:48:04.558847 139739648632704 efficientnet_model.py:143] round_filter input=112 output=200\n","I0521 06:48:05.271577 139739648632704 efficientnet_model.py:143] round_filter input=112 output=200\n","I0521 06:48:05.271797 139739648632704 efficientnet_model.py:143] round_filter input=192 output=344\n","I0521 06:48:06.344610 139739648632704 efficientnet_model.py:143] round_filter input=192 output=344\n","I0521 06:48:06.344897 139739648632704 efficientnet_model.py:143] round_filter input=320 output=576\n","I0521 06:48:07.358906 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I0521 06:48:07.390314 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0521 06:48:07.499433 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0521 06:48:07.499632 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0521 06:48:07.499711 139739648632704 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0521 06:48:07.501435 139739648632704 efficientnet_model.py:143] round_filter input=32 output=64\n","I0521 06:48:07.518603 139739648632704 efficientnet_model.py:143] round_filter input=32 output=64\n","I0521 06:48:07.518754 139739648632704 efficientnet_model.py:143] round_filter input=16 output=32\n","I0521 06:48:08.159553 139739648632704 efficientnet_model.py:143] round_filter input=16 output=32\n","I0521 06:48:08.159808 139739648632704 efficientnet_model.py:143] round_filter input=24 output=48\n","I0521 06:48:09.178997 139739648632704 efficientnet_model.py:143] round_filter input=24 output=48\n","I0521 06:48:09.179236 139739648632704 efficientnet_model.py:143] round_filter input=40 output=80\n","I0521 06:48:10.044140 139739648632704 efficientnet_model.py:143] round_filter input=40 output=80\n","I0521 06:48:10.044381 139739648632704 efficientnet_model.py:143] round_filter input=80 output=160\n","I0521 06:48:11.919301 139739648632704 efficientnet_model.py:143] round_filter input=80 output=160\n","I0521 06:48:11.923916 139739648632704 efficientnet_model.py:143] round_filter input=112 output=224\n","I0521 06:48:13.583521 139739648632704 efficientnet_model.py:143] round_filter input=112 output=224\n","I0521 06:48:13.583719 139739648632704 efficientnet_model.py:143] round_filter input=192 output=384\n","I0521 06:48:16.033120 139739648632704 efficientnet_model.py:143] round_filter input=192 output=384\n","I0521 06:48:16.033385 139739648632704 efficientnet_model.py:143] round_filter input=320 output=640\n","I0521 06:48:16.586861 139739648632704 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I0521 06:48:16.617062 139739648632704 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.6s\n","I0521 06:48:16.745896 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.6s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0521 06:48:16.752247 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0521 06:48:16.754106 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0521 06:48:16.754660 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0521 06:48:16.756145 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0521 06:48:16.757485 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0521 06:48:16.758071 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0521 06:48:16.759152 139739648632704 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 34.907s\n","\n","OK (skipped=1)\n"]}],"source":["VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n","# Verify Installation\n","!python {VERIFICATION_SCRIPT}"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":69168,"status":"ok","timestamp":1653116351901,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"WDkr_bbQp7-q","outputId":"08c92b44-59f1-4adb-fa2b-a6b5ae5fa73f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.1)\n","Collecting tensorflow-gpu==2.7.0\n","  Using cached tensorflow_gpu-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.6.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (3.1.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (2.8.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.46.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (4.2.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.21.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (0.2.0)\n","Collecting keras<2.8,>=2.7.0rc0\n","  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.1.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (0.26.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (0.37.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (3.20.1)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.12)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (14.0.1)\n","Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n","  Using cached tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (0.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.7.0) (1.14.1)\n","Collecting tensorflow\n","  Using cached tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Collecting tensorboard~=2.6\n","  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n","Collecting tensorflow\n","  Using cached tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n","  Using cached tensorflow-2.7.2-cp37-cp37m-manylinux2010_x86_64.whl (495.4 MB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu==2.7.0) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.11.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.2.0)\n","Installing collected packages: tensorflow-estimator, keras, tensorflow-gpu, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: tensorflow-gpu\n","    Found existing installation: tensorflow-gpu 2.9.0\n","    Uninstalling tensorflow-gpu-2.9.0:\n","      Successfully uninstalled tensorflow-gpu-2.9.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.1\n","    Uninstalling tensorflow-2.8.1:\n","      Successfully uninstalled tensorflow-2.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-models-official 2.9.2 requires tensorflow~=2.9.0, but you have tensorflow 2.7.2 which is incompatible.\n","tensorflow-text 2.9.0 requires tensorflow<2.10,>=2.9.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.7.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.7.0 tensorflow-2.7.2 tensorflow-estimator-2.7.0 tensorflow-gpu-2.7.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install tensorflow tensorflow-gpu==2.7.0 "]},{"cell_type":"code","source":["!pip install --upgrade tensorflow-gpu==2.9.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HkzjU5L_X4iR","executionInfo":{"status":"ok","timestamp":1653115760546,"user_tz":-330,"elapsed":30154,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"}},"outputId":"0463200a-5ac5-44c1-f45f-a0c5fecbce27"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu==2.9.0\n","  Downloading tensorflow_gpu-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (0.26.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (14.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (4.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (3.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (21.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (0.2.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (0.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.6.3)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (2.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.1.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.12)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.46.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (3.20.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (57.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.14.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.1.2)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (2.9.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.21.6)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (1.0.0)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.9.0) (2.9.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu==2.9.0) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu==2.9.0) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (3.3.7)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (2.27.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (0.6.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu==2.9.0) (3.0.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (4.11.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (2021.10.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9.0) (3.2.0)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.9.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":15908,"status":"ok","timestamp":1653115785225,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"ePT0oAw8p7-r","outputId":"2b926c1d-571f-4dd4-eece-ce9aab88ac2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: protobuf 3.20.1\n","Uninstalling protobuf-3.20.1:\n","  Successfully uninstalled protobuf-3.20.1\n","Found existing installation: matplotlib 3.2.2\n","Uninstalling matplotlib-3.2.2:\n","  Successfully uninstalled matplotlib-3.2.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting protobuf\n","  Using cached protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","Collecting matplotlib\n","  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fonttools>=4.22.0\n","  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.9/930.9 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n","Installing collected packages: protobuf, fonttools, matplotlib\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fonttools-4.33.3 matplotlib-3.5.2 protobuf-3.20.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip uninstall protobuf matplotlib -y\n","!pip install protobuf matplotlib --upgrade"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":425,"status":"ok","timestamp":1653115837088,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"w8ElaoKFp7-s"},"outputs":[],"source":["import object_detection"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3450,"status":"ok","timestamp":1653115843121,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"rpLJaetogFD6","outputId":"66897b43-a9ce-4111-b354-275394bd15e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless==4.5.5.64 in /usr/local/lib/python3.7/dist-packages (4.5.5.64)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.5.64) (1.21.6)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["pip install opencv-python-headless==4.5.5.64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G5hwMY4p7-s","scrolled":true},"outputs":[],"source":["!pip list"]},{"cell_type":"code","source":["!pip install numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IDdRkjRfYf3G","executionInfo":{"status":"ok","timestamp":1653115865851,"user_tz":-330,"elapsed":6970,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"}},"outputId":"588810bd-0e11-4ea6-f68e-0bd3ba5b2b60"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1461,"status":"ok","timestamp":1653115881833,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"csofht2npfDE","outputId":"1d0fb785-04d1-4892-fa71-22f0d48d1f7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-21 06:51:20--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.213.128, 2607:f8b0:400c:c05::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.213.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20515344 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.56M  91.9MB/s    in 0.2s    \n","\n","2022-05-21 06:51:20 (91.9 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n","\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"]}],"source":["if os.name =='posix':\n","    !wget {PRETRAINED_MODEL_URL}\n","    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n","if os.name == 'nt':\n","    wget.download(PRETRAINED_MODEL_URL)\n","    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"]},{"cell_type":"code","source":["/content/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py"],"metadata":{"id":"WUMZshIEUoMS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5KJTnkfpfDC"},"source":["# 2. Create Label Map"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1653115901241,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"p1BVDWo7pfDC"},"outputs":[],"source":["labels = [{'name':'licence', 'id':1}]\n","\n","with open(files['LABELMAP'], 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"]},{"cell_type":"markdown","metadata":{"id":"C88zyVELpfDC"},"source":["# 3. Create TF records"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1653115903865,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"kvf5WccwrFGq"},"outputs":[],"source":["ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n","if os.path.exists(ARCHIVE_FILES):\n","  !tar -zxvf {ARCHIVE_FILES}"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6756,"status":"ok","timestamp":1653116007447,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"UPFToGZqpfDD","outputId":"f8d20437-3599-4b2a-a16c-3bef8f4b423c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n","Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"]}],"source":["!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n","!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "]},{"cell_type":"markdown","metadata":{"id":"qT4QU7pLpfDE"},"source":["# 4. Copy Model Config to Training Folder"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1653116011149,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"cOjuTFbwpfDF"},"outputs":[],"source":["if os.name =='posix':\n","    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n","if os.name == 'nt':\n","    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"]},{"cell_type":"markdown","metadata":{"id":"Ga8gpNslpfDF"},"source":["# 5. Update Config For Transfer Learning"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3108,"status":"ok","timestamp":1653116018472,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"Z9hRrO_ppfDF"},"outputs":[],"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1653116020056,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"c2A0mn4ipfDF"},"outputs":[],"source":["config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":647,"status":"ok","timestamp":1653116022317,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"uQA13-afpfDF","outputId":"d9770766-5c9d-4cf1-923f-8cec0c9943da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false,\n"," 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 320\n","       width: 320\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," },\n"," 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }}"]},"metadata":{},"execution_count":25}],"source":["config"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":385,"status":"ok","timestamp":1653116026306,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"9vK5lotDpfDF"},"outputs":[],"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1653116029121,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"rP43Ph0JpfDG"},"outputs":[],"source":["pipeline_config.model.ssd.num_classes = len(labels)\n","pipeline_config.train_config.batch_size = 4\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653116031609,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"oJvfgwWqpfDG"},"outputs":[],"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5053,"status":"ok","timestamp":1653116038996,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"uO6ICv7vIh_b","outputId":"d15473e9-3847-4c3d-b6b3-9764c5d76376"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless==4.1.2.30\n","  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n","Installing collected packages: opencv-python-headless\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.5.5.64\n","    Uninstalling opencv-python-headless-4.5.5.64:\n","      Successfully uninstalled opencv-python-headless-4.5.5.64\n","Successfully installed opencv-python-headless-4.1.2.30\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["pip install opencv-python-headless==4.1.2.30"]},{"cell_type":"markdown","metadata":{"id":"Zr3ON7xMpfDG"},"source":["# 6. Train the model"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1653116042975,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"B-Y2UQmQpfDG"},"outputs":[],"source":["TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1653116045915,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"jMP2XDfQpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=6000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1653116048401,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"},"user_tz":-330},"id":"A4OXXi-ApfDH","outputId":"9bd28f39-79b4-4782-d275-13d2dc27138c"},"outputs":[{"output_type":"stream","name":"stdout","text":["python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=6000\n"]}],"source":["print(command)"]},{"cell_type":"code","source":["pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtqWMZFoVeVT","executionInfo":{"status":"ok","timestamp":1653116057877,"user_tz":-330,"elapsed":7238,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"}},"outputId":"63045a74-e28f-44e7-eef2-d1c5309ed625"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install tensorflow-addons[tensorflow]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_k0y3g_Vk1W","executionInfo":{"status":"ok","timestamp":1653116101354,"user_tz":-330,"elapsed":40312,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"}},"outputId":"d30bbac3-0426-48d4-a77e-7077d56fd876"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-addons[tensorflow] in /usr/local/lib/python3.7/dist-packages (0.16.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons[tensorflow]) (2.7.1)\n","Collecting tensorflow<2.9.0,>=2.6.0\n","  Downloading tensorflow-2.8.1-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.9/497.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.12)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.14.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.0.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.6.3)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.4.0)\n","Collecting tensorflow-estimator<2.9,>=2.8\n","  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (4.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (3.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (14.0.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.15.0)\n","Collecting keras<2.9,>=2.8.0rc0\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (3.20.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.46.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.26.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.21.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (57.4.0)\n","Collecting tensorboard<2.9,>=2.8\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (2.27.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (3.3.7)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.8.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (4.11.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.6.0->tensorflow-addons[tensorflow]) (3.2.0)\n","Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.0\n","    Uninstalling tensorboard-2.9.0:\n","      Successfully uninstalled tensorboard-2.9.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.0\n","    Uninstalling tensorflow-2.9.0:\n","      Successfully uninstalled tensorflow-2.9.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-models-official 2.9.2 requires tensorflow~=2.9.0, but you have tensorflow 2.8.1 which is incompatible.\n","tensorflow-text 2.9.0 requires tensorflow<2.10,>=2.9.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.1 which is incompatible.\n","tensorflow-gpu 2.9.0 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.8.0 which is incompatible.\n","tensorflow-gpu 2.9.0 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.8.0 which is incompatible.\n","tensorflow-gpu 2.9.0 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.1 tensorflow-estimator-2.8.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3ZsJR-qpfDH","executionInfo":{"status":"ok","timestamp":1653116414368,"user_tz":-330,"elapsed":52277,"user":{"displayName":"Shruti Pangare","userId":"03038613899014573524"}},"outputId":"8dee5038-cb61-4138-c711-80d4d255b73b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-05-21 06:59:33.387341: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0521 06:59:33.391919 140134074423168 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 6000\n","I0521 06:59:33.398554 140134074423168 config_util.py:552] Maybe overwriting train_steps: 6000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0521 06:59:33.398797 140134074423168 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0521 06:59:33.429844 140134074423168 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n","I0521 06:59:33.434484 140134074423168 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n","I0521 06:59:33.434746 140134074423168 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0521 06:59:33.434861 140134074423168 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0521 06:59:33.434941 140134074423168 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0521 06:59:33.577566 140134074423168 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0521 06:59:33.601926 140134074423168 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0521 06:59:41.127776 140134074423168 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0521 06:59:44.557591 140134074423168 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0521 06:59:46.242998 140134074423168 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","2022-05-21 06:59:50.611863: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","Cleanup called...\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2022-05-21 07:00:12.032784: E tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n","2022-05-21 07:00:12.034186: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNKNOWN: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n","Traceback (most recent call last):\n","  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 111, in main\n","    record_summaries=FLAGS.record_summaries)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 609, in train_loop\n","    train_input, unpad_groundtruth_tensors)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 401, in load_fine_tune_checkpoint\n","    _ensure_model_is_built(model, input_dataset, unpad_groundtruth_tensors)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 179, in _ensure_model_is_built\n","    labels,\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1316, in run\n","    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2892, in call_for_each_replica\n","    return self._call_for_each_replica(fn, args, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 678, in _call_for_each_replica\n","    self._container_strategy(), fn, args, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 86, in call_for_each_replica\n","    return wrapped(args, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n","    inputs, attrs, num_outputs)\n","tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n","\t [[node ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D\n"," (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py:238)\n","]] [Op:__inference__dummy_computation_fn_15086]\n","\n","Errors may have originated from an input operation.\n","Input Source operations connected to node ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D:\n","In[0] args_1 (defined at /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:179)\t\n","In[1] ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D/ReadVariableOp:\n","\n","Operation defined at: (most recent call last)\n",">>>   File \"/usr/lib/python3.7/threading.py\", line 890, in _bootstrap\n",">>>     self._bootstrap_inner()\n",">>> \n",">>>   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",">>>     self.run()\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 171, in _dummy_computation_fn\n",">>>     return _compute_losses_and_predictions_dicts(model, features, labels,\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 124, in _compute_losses_and_predictions_dicts\n",">>>     prediction_dict = model.predict(\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 569, in predict\n",">>>     if self._feature_extractor.is_keras_model:\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 570, in predict\n",">>>     feature_maps = self._feature_extractor(preprocessed_inputs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",">>>     return fn(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n",">>>     outputs = call_fn(inputs, *args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",">>>     return fn(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 251, in call\n",">>>     return self._extract_features(inputs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 218, in _extract_features\n",">>>     image_features = self.classification_backbone(\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",">>>     return fn(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n",">>>     outputs = call_fn(inputs, *args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",">>>     return fn(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n",">>>     inputs, training=training, mask=mask)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",">>>     outputs = node.layer(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",">>>     return fn(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n",">>>     outputs = call_fn(inputs, *args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",">>>     return fn(*args, **kwargs)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 246, in call\n",">>>     outputs = self.convolution_op(inputs, self.kernel)\n",">>> \n",">>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 238, in convolution_op\n",">>>     name=self.__class__.__name__)\n",">>> \n"]}],"source":["!{command}"]},{"cell_type":"code","source":["gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try: \n","        tf.config.experimental.set_virtual_device_configuration(\n","            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n","    except RunTimeError as e:\n","        print(e)"],"metadata":{"id":"SR4NlS2rWtIl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_YRZu7npfDH"},"source":["# 7. Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80L7-fdPpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYsgEPx9pfDH"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqTV2jGBpfDH"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eudHJaDcK0y"},"outputs":[],"source":["https://www.tensorflow.org/alpha/guide/upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWoB71ZOu59H"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"orvRk02UpfDI"},"source":["# 8. Load Train Model From Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TYk4_oIpfDI"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3t0CJWYUf6c"},"outputs":[],"source":["gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try: \n","      tf.config.experimental.set_virtual_device_configuration(\n","            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n","    except RunTimeError as e:\n","      print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehszzc_gZkAv"},"outputs":[],"source":["!pip install -q tflite-model-maker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDnQg-cYpfDI"},"outputs":[],"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"]},{"cell_type":"markdown","metadata":{"id":"zSriqyIlS69G"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"0EmsmbBZpfDI"},"source":["# 9. Detect from an Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_MKiuZ4pfDI"},"outputs":[],"source":["import cv2 \n","import numpy as np\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rfwgw5rf68FM"},"outputs":[],"source":["!pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio===0.9.1 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MK0lUYN6mh9"},"outputs":[],"source":["!pip install easyocr --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBDbIhNapfDI"},"outputs":[],"source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lx3crOhOzITB"},"outputs":[],"source":["IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'Cars9.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8YFO_HuEtx7"},"outputs":[],"source":["!pip install matplotlib==3.1.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jmK7Y1VEydl"},"outputs":[],"source":["tf.config.run_functions_eagerly(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tpzn1SMry1yK"},"outputs":[],"source":["img = cv2.imread(IMAGE_PATH)\n","image_np = np.array(img)\n","\n","input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections = detect_fn(input_tensor)\n","\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","              for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","            image_np_with_detections,\n","            detections['detection_boxes'],\n","            detections['detection_classes']+label_id_offset,\n","            detections['detection_scores'],\n","            category_index,\n","            use_normalized_coordinates=True,\n","            max_boxes_to_draw=5,\n","            min_score_thresh=.8,\n","            agnostic_mode=False)\n","\n","plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDioy-JYVIgz"},"outputs":[],"source":["import xml\n","from xml.etree import ElementTree\n","XML_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'Cars9.xml')\n","xml_tree = xml.etree.ElementTree.parse(XML_PATH)\n","root = xml_tree.getroot()\n","\n","def recursive_print(element, indent):\n","    element_tag = element.tag\n","    element_attributes = element.attrib if len(element.attrib) else \"\"\n","    element_text = element.text if element.text is not None and '0' and len(element.text.strip()) > 0 else \"\"\n","    element_tail = element.tail.strip() if element.tail is not None and '0' and len(element.tail.strip()) > 0 else \"\"\n","\n","    print(\n","        \" \"*indent,\n","        #element_tag.title(), \n","        element_attributes, element_text\n","        #element_tail\n","    )\n","#tree = ElementTree.fromstring(data)\n","#print('Country:', tree.find('country').text)\n","    element_children = list(element)\n","    for child in element_children:\n","      for subelement in child:\n","          recursive_print(subelement, indent + 2)\n","      #print('Country:', child.find('country').element_text)\n","\n","recursive_print(root, 0)"]},{"cell_type":"markdown","metadata":{"id":"_veG6YMl6MzF"},"source":["detections\n","detections"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkbSjc6V6W4O"},"outputs":[],"source":["detections.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDX8IO0Z9KqQ"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0impBrC19Mwo"},"outputs":[],"source":["import easyocr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3TkXawS9Ykz"},"outputs":[],"source":["detection_threshold = 0.7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFAW-1hJDiKQ"},"outputs":[],"source":["image = image_np_with_detections\n","scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n","boxes = detections['detection_boxes'][:len(scores)]\n","classes = detections['detection_classes'][:len(scores)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1IsG0KHiDi9J"},"outputs":[],"source":["width = image.shape[1]\n","height = image.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dD87dXveDjJK"},"outputs":[],"source":["for idx, box in enumerate(boxes):\n","    print(box)\n","    roi = box*[height, width, height, width]\n","    print(roi)\n","    region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n","    reader = easyocr.Reader(['en'])\n","    ocr_result = reader.readtext(region)\n","    print(ocr_result)\n","    plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5m15bxnKkEUy"},"outputs":[],"source":["for result in ocr_result:\n","  print(np.sum(np.subtract(result[0][2],result[0][1])))\n","  print(result[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfsW0XCKDtni"},"outputs":[],"source":["region_threshold = 0.05"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3P1_4ofDtyf"},"outputs":[],"source":["def filter_text(region, ocr_result, region_threshold):\n","    rectangle_size = region.shape[0]*region.shape[1]\n","    \n","    plate = [] \n","    for result in ocr_result:\n","        length = np.sum(np.subtract(result[0][1], result[0][0]))\n","        height = np.sum(np.subtract(result[0][2], result[0][1]))\n","        \n","        if length*height / rectangle_size > region_threshold:\n","            plate.append(result[1])\n","    return plate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAcUkKSTEMZ3"},"outputs":[],"source":["fil_text= filter_text(region, ocr_result, region_threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlcHSO3IOrrN"},"outputs":[],"source":["fil_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlwBetfoGiXy"},"outputs":[],"source":["region_threshold = 0.6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYsnYjvNGoLV"},"outputs":[],"source":["import xml\n","from xml.etree import ElementTree\n","XML_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'Cars9.xml')\n","xml_tree = xml.etree.ElementTree.parse(XML_PATH)\n","root = xml_tree.getroot()\n","\n","def recursive_print(element, indent):\n","    element_tag = element.tag\n","    element_attributes = element.attrib if len(element.attrib) else \"\"\n","    element_text = element.text if element.text is not None and '0' and len(element.text.strip()) > 0 else \"\"\n","    element_tail = element.tail.strip() if element.tail is not None and '0' and len(element.tail.strip()) > 0 else \"\"\n","\n","    print(\n","        \" \"*indent,\n","        #element_tag.title(), \n","        element_attributes, element_text\n","        #element_tail\n","    )\n","#tree = ElementTree.fromstring(data)\n","#print('Country:', tree.find('country').text)\n","    element_children = list(element)\n","    for child in element_children:\n","      for subelement in child:\n","          recursive_print(subelement, indent + 2)\n","      #print('Country:', child.find('country').element_text)\n","\n","recursive_print(root, 0)\n","\n","import datetime\n","date = datetime.datetime.now()\n","print(\"Date and time: \",date)\n","\n","\n","def ocr_it(image, detections, detection_threshold, region_threshold):\n","    \n","    # Scores, boxes and classes above threhold\n","    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n","    boxes = detections['detection_boxes'][:len(scores)]\n","    classes = detections['detection_classes'][:len(scores)]\n","    \n","    # Full image dimensions\n","    width = image.shape[1]\n","    height = image.shape[0]\n","    \n","    # Apply ROI filtering and OCR\n","    for idx, box in enumerate(boxes):\n","        roi = box*[height, width, height, width]\n","        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n","        reader = easyocr.Reader(['en'])\n","        ocr_result = reader.readtext(region)\n","        \n","        text = filter_text(region, ocr_result, region_threshold)\n","        \n","        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n","        plt.show()\n","        print(text)\n","        return text, region"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1IOnpuVMGuzF"},"outputs":[],"source":["text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)"]},{"cell_type":"markdown","metadata":{"id":"Rr82SzoS6WRO"},"source":["### Saving of Result:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCUWKYtRj0Gq"},"outputs":[],"source":["import csv \n","import uuid\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgbSN57mmirX"},"outputs":[],"source":["'{}.jpg'.format(uuid.uuid1())\n","#'{}.jpg'.format(fil_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goMstcOsmnsm"},"outputs":[],"source":["import datetime\n","date = datetime.datetime.now()\n","def save_results(filter_text,region,csv_filename,folder_path,date):\n","  img_name='{}.jpg'.format(uuid.uuid1())\n","  #img_name='{}.jpg'.format(fil_text)\n","  cv2.imwrite(os.path.join(folder_path,img_name),region)\n","\n","  with open(csv_filename,mode='a',newline='')as f:\n","    csv_writer= csv.writer(f,delimiter=',',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n","    csv_writer.writerow([img_name,filter_text])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0KOXjvMohX2"},"outputs":[],"source":["region"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gspwVfB4ojSl"},"outputs":[],"source":["save_results(filter_text, region,' Detection_results.csv' ,'Detected Images',date)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFepzxfnpFfd"},"outputs":[],"source":["filter_text"]},{"cell_type":"markdown","metadata":{"id":"IsNAaYAo0WVL"},"source":["# 10. Real Time Detections from your Webcam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8GxIa-Cp7--"},"outputs":[],"source":["!pip uninstall opencv-python-headless -y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3a4XCG9IrRB"},"outputs":[],"source":["import xml\n","from xml.etree import ElementTree\n","XML_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'Cars9.xml')\n","xml_tree = xml.etree.ElementTree.parse(XML_PATH)\n","root = xml_tree.getroot()\n","\n","def recursive_print(element, indent):\n","    element_tag = element.tag\n","    element_attributes = element.attrib if len(element.attrib) else \"\"\n","    element_text = element.text if element.text is not None and '0' and len(element.text.strip()) > 0 else \"\"\n","    element_tail = element.tail.strip() if element.tail is not None and '0' and len(element.tail.strip()) > 0 else \"\"\n","\n","    print(\n","        \" \"*indent,\n","        #element_tag.title(), \n","        element_attributes, element_text\n","        #element_tail\n","    )\n","#tree = ElementTree.fromstring(data)\n","#print('Country:', tree.find('country').text)\n","    element_children = list(element)\n","    for child in element_children:\n","      for subelement in child:\n","          recursive_print(subelement, indent + 2)\n","      #print('Country:', child.find('country').element_text)\n","\n","recursive_print(root, 0)\n","\n","import datetime\n","date = datetime.datetime.now()\n","print(\"Date and time: \",date)\n","\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TtcUjC8fKNeJ"},"outputs":[],"source":["from IPython.display import Image\n","try:\n","  filename = take_photo()\n","  print('Saved to {}'.format(filename))\n","  \n","  # Show the image which was just taken.\n","  display(Image(filename))\n","except Exception as err:\n","  # Errors will be thrown if the user does not have a webcam or if they do not\n","  # grant the page permission to access it.\n","  print(str(err))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_kXtaLxK7KN"},"outputs":[],"source":["from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_etha1RS5iM"},"outputs":[],"source":["pip install opencv-contrib-python --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxdunGL6NCYh"},"outputs":[],"source":["def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NGwxA1a-CgH"},"outputs":[],"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_H7ukQrNF8G"},"outputs":[],"source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","    image_np = np.array(frame)\n","\n","    # create transparent overlay for bounding box\n","    ##bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","    \n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.8,\n","                agnostic_mode=False)\n","\n","    try: \n","        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n","        save_results(text, region, 'realtimeresults.csv', 'Detection_Images',date)\n","        import datetime\n","        date = datetime.datetime.now()\n","        print(\"Date and time: \",date)\n","    except:\n","        pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_grs6OGpfDJ"},"outputs":[],"source":["import cv2\n","...\n","VIDEO_STREAM = \"/content/vehicles.mp4\"\n","VIDEO_STREAM_OUT = \"/content/drive/My Drive/Colab Notebooks/Result.avi\"\n","...\n","# initialize the video stream and pointer to output video file\n","cap = cv2.VideoCapture(VIDEO_STREAM)\n","writer = None\n","cap.set(cv2.CAP_PROP_POS_FRAMES, 1000);\n","\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","while cap.isOpened(): \n","    ret, frame = cap.read()\n","    image_np = np.array(frame)\n","    \n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","    \n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.8,\n","                agnostic_mode=False)\n","\n","    try: \n","        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n","        save_results(text, region, 'realtimeresults.csv', 'Detection_Images')\n","    except:\n","        pass\n","\n","    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","    \n","    if cv2.waitKey(10) & 0xFF == ord('q'):\n","        cap.release()\n","        cv2.destroyAllWindows()\n","        break"]},{"cell_type":"markdown","metadata":{"id":"rzlM4jt0pfDJ"},"source":["# 10. Freezing the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4olHB2npfDJ"},"outputs":[],"source":["FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AjO93QDpfDJ"},"outputs":[],"source":["command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6Lsp3tCpfDJ"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Sw1ULgHpfDJ"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"wTPmdqaXpfDK"},"source":["# 11. Conversion to TFJS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ6UzY_fpfDK","scrolled":true},"outputs":[],"source":["!pip install tensorflowjs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oxbVynHpfDK"},"outputs":[],"source":["command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DB2AGNmJpfDK"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7rfT4-hpfDK"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8_hm-itpfDK"},"outputs":[],"source":["# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"]},{"cell_type":"markdown","metadata":{"id":"VtUw73FHpfDK"},"source":["# 12. Conversion to TFLite"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XviMtewLpfDK"},"outputs":[],"source":["TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us86cjC4pfDL"},"outputs":[],"source":["command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1r5YO3rpfDL"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-xWpHN8pfDL"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJfYMbN6pfDL"},"outputs":[],"source":["FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n","TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO0PRth-p7_E"},"outputs":[],"source":["command = \"tflite_convert \\\n","--saved_model_dir={} \\\n","--output_file={} \\\n","--input_shapes=1,300,300,3 \\\n","--input_arrays=normalized_input_image_tensor \\\n","--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n","--inference_type=FLOAT \\\n","--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8GwUeoFpfDL"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nbd7gqHMpfDL"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"5NQqZRdA21Uc"},"source":["# 13. Zip and Export Models "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTVTGCQp2ZJJ"},"outputs":[],"source":["!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whShhB0x3PYJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["4_YRZu7npfDH","IsNAaYAo0WVL","rzlM4jt0pfDJ","wTPmdqaXpfDK","VtUw73FHpfDK","5NQqZRdA21Uc"],"name":"ANPR Training and Detection-checkpoint.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}